import { useRef, useState } from 'react';

const SttStreaming_2 = () => {
  // ìµœì¢… í™•ì •ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ìƒíƒœ. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.
  const [finalVoiceText, setFinalVoiceText] = useState<string>('');
  // í˜„ì¬ ë§í•˜ê³  ìˆëŠ” ì¤‘ì¸ ì ì •ì ì¸ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ìƒíƒœ. ê³„ì† ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
  const [interimVoiceText, setInterimVoiceText] = useState<string>('');

  const [isTalking, setIsTalking] = useState<boolean>(false);
  const [isListening, setIsListening] = useState<boolean>(false);

  const webSocket = useRef<WebSocket | null>(null);
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioContext = useRef<AudioContext | null>(null);
  const processor = useRef<AudioWorkletNode | null>(null);
  const audioChunks = useRef<Uint8Array[]>([]);
  const stream = useRef<MediaStream | null>(null);
  const source = useRef<MediaStreamAudioSourceNode | null>(null);
  const analyser = useRef<AnalyserNode | null>(null);

  const closeWebSocket = () => {
    if (webSocket.current) {
      webSocket.current.close();
      webSocket.current = null;
    }
    setIsListening(false);
    // ì—°ê²° ì¢…ë£Œ ì‹œ í…ìŠ¤íŠ¸ ìƒíƒœ ì´ˆê¸°í™”
    // setFinalVoiceText('');
    setInterimVoiceText('');
  };

  const setupWebSocket = async () => {
    closeWebSocket(); // ê¸°ì¡´ ì—°ê²°ì´ ìˆë‹¤ë©´ ë‹«ê³  ìƒíƒœ ì´ˆê¸°í™”

    const ws = new WebSocket('ws://localhost:8099/ws/speech');

    ws.onopen = async () => {
      try {
        const sampleRate = 16000;
        const chunkRate = 100;

        // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° ìŠ¤íŠ¸ë¦¼ ìƒì„±
        stream.current = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: sampleRate,
            channelCount: 1,
            echoCancellation: true,
          },
        });

        mediaRecorder.current = new MediaRecorder(stream.current);

        // AudioContext ìƒì„±
        audioContext.current = new (window.AudioContext || (window as any).webkitAudioContext)({
          sampleRate: sampleRate,
        });

        // AudioWorklet ëª¨ë“ˆ ë¡œë“œ
        // '/linear16-processor.js' íŒŒì¼ì´ ì›¹ ì„œë²„ì˜ ë£¨íŠ¸ ê²½ë¡œì— ì˜¬ë°”ë¥´ê²Œ ìœ„ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        await audioContext.current.audioWorklet.addModule('/linear16-processor.js');

        // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
        source.current = audioContext.current.createMediaStreamSource(stream.current);

        // AudioWorkletNode ìƒì„±
        processor.current = new AudioWorkletNode(
          audioContext.current,
          'linear16-processor'
        );

        // ë³€í™˜ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì›¹ì†Œì¼“ìœ¼ë¡œ ì „ì†¡
        processor.current.port.onmessage = (event: MessageEvent) => {
          if (webSocket.current && webSocket.current.readyState === WebSocket.OPEN) {
            webSocket.current.send(event.data);
            audioChunks.current.push(new Int16Array(event.data) as unknown as Uint8Array);
          }
        };

        // ìŒì„± í™œë™ ê°ì§€ë¥¼ ìœ„í•œ Analyser ì„¤ì •
        analyser.current = audioContext.current.createAnalyser();
        analyser.current.fftSize = 256;
        const dataArray = new Uint8Array(analyser.current.frequencyBinCount);

        // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²°
        source.current.connect(processor.current);
        processor.current.connect(audioContext.current.destination);
        source.current.connect(analyser.current);

        // ìŒì„± í™œë™ ê°ì§€ í•¨ìˆ˜
        const detectTalking = () => {
          if (!webSocket.current || !analyser.current) {
            return;
          }

          analyser.current.getByteFrequencyData(dataArray);
          // í‰ê·  ë³¼ë¥¨ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²•)
          const avgVolume = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;

          if (avgVolume > 30) { // ì„ê³„ê°’ 30ì€ í™˜ê²½ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”
            setIsTalking(true);
          } else {
            setIsTalking(false);
          }

          // ë‹¤ìŒ í”„ë ˆì„ì—ì„œ í•¨ìˆ˜ ë‹¤ì‹œ í˜¸ì¶œ
          requestAnimationFrame(detectTalking);
        };

        detectTalking(); // ìŒì„± í™œë™ ê°ì§€ ì‹œì‘

        // MediaRecorder ì •ì§€ í•¸ë“¤ëŸ¬ (AudioWorkletNodeë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ MediaRecorderëŠ” ì‚¬ì‹¤ìƒ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        // ê·¸ëŸ¬ë‚˜ ìŠ¤íŠ¸ë¦¼ì„ ê´€ë¦¬í•˜ê³  ì •ë¦¬í•˜ëŠ” ìš©ë„ë¡œ ìœ ì§€
        mediaRecorder.current.onstop = () => {
          if (processor.current && audioContext.current && source.current && stream.current) {
            stream.current.getTracks().forEach((track) => track.stop()); // ìŠ¤íŠ¸ë¦¼ì˜ ëª¨ë“  íŠ¸ë™ ì¤‘ì§€
            source.current.disconnect(processor.current); // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
            processor.current.disconnect(audioContext.current.destination);
          }
        };

        mediaRecorder.current.start(chunkRate); // MediaRecorder ì‹œì‘ (AudioWorklet ì‚¬ìš© ì‹œ ì˜¤ë””ì˜¤ ë°ì´í„° ìì²´ëŠ” ì—¬ê¸°ì„œ ì˜¤ì§€ ì•ŠìŒ)
        setIsListening(true);
      } catch (error) {
        console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
        alert('ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      }
    };

    ws.onmessage = (event: MessageEvent) => {
      try {
        // ë°±ì—”ë“œì—ì„œ ë³´ë‚¸ JSON ë°ì´í„° íŒŒì‹±: { transcript: "...", isFinal: true/false }
        const data: { transcript: string; isFinal: boolean } = JSON.parse(event.data);

        if (data.isFinal) {
          // ìµœì¢… ê²°ê³¼ì¸ ê²½ìš°:
          // 1. ìµœì¢… í…ìŠ¤íŠ¸ì— í˜„ì¬ ìµœì¢… ê²°ê³¼ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. (ë’¤ì— ê³µë°± ì¶”ê°€)
          setFinalVoiceText((prev) => prev + data.transcript + ' ');
          // 2. ì ì • í…ìŠ¤íŠ¸ëŠ” ë¹„ì›ë‹ˆë‹¤.
          setInterimVoiceText('');
        } else {
          // ì ì • ê²°ê³¼ì¸ ê²½ìš°:
          // 1. ì ì • í…ìŠ¤íŠ¸ë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ìµœì¢… í…ìŠ¤íŠ¸ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
          setInterimVoiceText(data.transcript);
        }
      } catch (error) {
        console.error('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
      }
    };

    ws.onerror = (error: Event) => {
      console.error('WebSocket ì˜¤ë¥˜:', error);
      setFinalVoiceText('');
      setInterimVoiceText('');
    };

    ws.onclose = () => {
      console.log('WebSocket ì—°ê²° ì¢…ë£Œ');

      // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      if (processor.current) {
        processor.current.disconnect();
        processor.current = null;
      }
      if (audioContext.current) {
        audioContext.current.close();
        audioContext.current = null;
      }
      if (mediaRecorder.current) {
        mediaRecorder.current.stop();
        mediaRecorder.current = null;
      }
      if (stream.current) {
        stream.current.getTracks().forEach(track => track.stop());
        stream.current = null;
      }

      setIsListening(false);
      setIsTalking(false);
      setFinalVoiceText('');
      setInterimVoiceText('');
    };

    webSocket.current = ws;
  };

  return (
    <div className="App">
      <header className="App-header">
        <h1>ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (STT)</h1>

        <div className="controls">
          <button
            onClick={setupWebSocket}
            disabled={isListening}
            className="btn btn-start"
          >
            {isListening ? 'ë“£ëŠ” ì¤‘...' : 'ë“£ê¸° ì‹œì‘'}
          </button>

          <button
            onClick={closeWebSocket}
            disabled={!isListening}
            className="btn btn-stop"
          >
            ë©ˆì¶”ê¸°
          </button>
        </div>

        <div className="status">
          {isListening && (
            <div className={`status-indicator ${isTalking ? 'talking' : ''}`}>
              {isTalking ? 'ğŸ¤ ë§í•˜ëŠ” ì¤‘...' : 'ğŸ”‡ ëŒ€ê¸° ì¤‘...'}
            </div>
          )}
        </div>

        <div className="transcript">
          <h2>ì¸ì‹ëœ í…ìŠ¤íŠ¸:</h2>
          <div className="transcript-text">
            {/* ìµœì¢… í™•ì •ëœ í…ìŠ¤íŠ¸ì™€ í˜„ì¬ ì ì •ì ì¸ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤. */}
            {finalVoiceText}
            {/* ì ì • í…ìŠ¤íŠ¸ëŠ” ìµœì¢… í…ìŠ¤íŠ¸ì™€ ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„ë˜ë„ë¡ ìŠ¤íƒ€ì¼ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. */}
            <span style={{color: 'gray'}}>{interimVoiceText}</span>
            {/* ì•„ë¬´ í…ìŠ¤íŠ¸ë„ ì—†ì„ ë•Œë§Œ ê¸°ë³¸ ë©”ì‹œì§€ í‘œì‹œ */}
            {!finalVoiceText && !interimVoiceText && 'ìŒì„±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”...'}
          </div>
        </div>
      </header>
    </div>
  );
};

export default SttStreaming_2;